{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. For which of the following problems would anomaly detection be a suitable algorithm?\n",
    "- From a large set of primary care patient records, identify individuals who might have unusual health conditions.\n",
    "- Given data from credit card transactions, classify each transaction according to type of purchase (for example: food, transportation, clothing).\n",
    "- Given a dataset of credit card transactions, identify unusual transactions to flag them as possibly fraudulent.\n",
    "- Given an image of a face, determine whether or not it is the face of a particular famous individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Suppose you have trained an anomaly detection system for fraud detection, and your system that flags anomalies when $p(x) < \\epsilon$, and you find on the cross-validation set that it mis-flagging far too many good transactions as fradulent. What should you do?\n",
    "1. Increase $\\epsilon$\n",
    "2. Decrease $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Suppose you are developing an anomaly detection system to catch manufacturing defects in airplane engines. You model uses $$\\Pi_{j=1}^n p(x_j;\\mu_j;\\sigma_j^2)$$ You have two features $x_1$ = vibration intensity, $x_2$ = heat generated, $0 < x_1 \\leq 1, 0 < x_2 \\leq 1$, for most \"normal\" engines you expect that $x_1 \\approx x_2$. One of the suspected anomalies is that a flawed engine may vibrate very intensely even without generating much heat (large $x_1$, small $x_2$), even though the particular values of $x_1$ and $x_2$ may not fall outside their typical ranges of values. What additional feature $x_3$ should you create to capture these types of anomalies:\n",
    "1. $x_3 = (x_1 + x_2)^2$\n",
    "2. $x_3 = x_1^2 \\times x_2^2$\n",
    "3. $x_3 = \\frac{x_1}{x_2}$\n",
    "4. $x_3 = x_1 \\times x_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Which of the following are true? Check all that apply.\n",
    "- If you are developing an anomaly detection system, there is no way to make use of labeled data to improve your system.\n",
    "- When choosing features for an anomaly detection system, it is a good idea to look for features that take on unusually large or small values for (mainly the) anomalous examples.\n",
    "- If you do not have any labeled data (or if all your data has label $y=0$), then is is still possible to learn $p(x)$, but it may be harder to evaluate the system or choose a good value of $\\epsilon$.\n",
    "- If you have a large labeled training set with many positive examples and many negative examples, the anomaly detection algorithm will likely perform just as well as a supervised learning algorithm such as an SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. You have a 1-D dataset $\\{x^{(1)}, \\ldots, x^{(m)}\\}$ and you want to detect outliers in the dataset. You first plot the dataset and it looks like this:\n",
    "<img src=\"../ee5JoL54EeSVRiIAC2sM-Q_Screen-Shot-2015-02-27-at-4.01.53-AM.png\"/>\n",
    "# Suppose you fit the gaussian distribution parameters $\\mu_1$ and $\\sigma_1^2$ to this dataset. Which of the following values for $\\mu_1$ and $\\sigma_1^2$ might you get?\n",
    "1. $\\mu_1 = -3, \\sigma_1^2 = 4$\n",
    "2. $\\mu_1 = -6, \\sigma_1^2 = 4$\n",
    "3. $\\mu_1 = -3, \\sigma_1^2 = 2$\n",
    "4. $\\mu_1 = -6, \\sigma_1^2 = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The Mahalanobis Method is one of the distance distribution-based techniques. What is the main assumption about the data?\n",
    "- The entire data set is normally distributed about its mean in the form of a multivariate Gaussian distribution.\n",
    "- Inliers are embedded in a lower-dimensional subspace. Data points that do not naturally fit this embedding model are, therefore, regarded as outliers.\n",
    "- Outliers are often hidden in the unusual local behavior of low-dimensional subspaces, and this deviant behavior is masked by full-dimensional analysis.\n",
    "- Outliers lie at the boundary of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. What methods of outlier detection would NOT be meaningful for processing of categorical data?\n",
    "- Extreme-value analysis and statistical algorithms.\n",
    "- Proximity-based algorithms with Euclidean distance.\n",
    "- Probabilistic Models with Bernoulli distribution.\n",
    "- Proximity-based algorithms with Inverse Occurrence Frequency distance.\n",
    "- Proximity-based algorithms with Contextual distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. What is FALSE when talking about outlier detection?\n",
    "- Often outlier detection can be concidered as highly balanced classification problem.\n",
    "- Outlier detection is largely an supervised learning problem.\n",
    "- The core principle of discovering outliers is based on assumptions about the structure of the **normal** patterns in a given data set.\n",
    "- Relationships among the different data points do not increase the difficulty of the problem of outlier detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
